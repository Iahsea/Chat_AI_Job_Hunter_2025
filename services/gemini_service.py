"""
Service xá»­ lÃ½ logic gá»i Google Gemini API
"""
import google.generativeai as genai
from typing import List, Dict
from config import get_settings, SYSTEM_PROMPT
from services.vector_service import search_jobs_vector



class GeminiService:
    """Service Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Google Gemini API"""
    
    def __init__(self):
        """Khá»Ÿi táº¡o Gemini client"""
        settings = get_settings()
        genai.configure(api_key=settings.GEMINI_API_KEY)
        
        # Cáº¥u hÃ¬nh generation vá»›i giá»›i háº¡n token
        generation_config = {
            "temperature": settings.ai_temperature,
            "max_output_tokens": settings.ai_max_tokens,  # Giá»›i háº¡n output
            "top_p": 0.95,
        }
        
        self.model = genai.GenerativeModel(
            settings.ai_model,
            generation_config=generation_config
        )
        print(f"âœ… Gemini initialized (max tokens: {settings.ai_max_tokens})")
    
    def build_conversation(
        self, 
        message: str, 
        conversation_history: List[Dict],
        jobs_info: str = ""
    ) -> str:
        """
        XÃ¢y dá»±ng chuá»—i conversation tá»« lá»‹ch sá»­ vÃ  tin nháº¯n má»›i
        
        Args:
            message: Tin nháº¯n hiá»‡n táº¡i tá»« user
            conversation_history: Lá»‹ch sá»­ há»™i thoáº¡i trÆ°á»›c Ä‘Ã³
            
        Returns:
            str: Chuá»—i conversation Ä‘áº§y Ä‘á»§ Ä‘á»ƒ gá»­i cho AI
        """
        conversation = SYSTEM_PROMPT + "\n\n"

        if jobs_info:
            conversation += f"CÃ¡c cÃ´ng viá»‡c phÃ¹ há»£p tá»« há»‡ thá»‘ng:\n{jobs_info}\n\n"
        else:
            conversation += "LÆ°u Ã½: Hiá»‡n táº¡i chÆ°a tÃ¬m tháº¥y cÃ´ng viá»‡c cá»¥ thá»ƒ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u. HÃ£y tÆ° váº¥n chung hoáº·c há»i thÃªm thÃ´ng tin.\n\n"
        
        # ThÃªm lá»‹ch sá»­ há»™i thoáº¡i
        if conversation_history:
            for msg in conversation_history:
                role = "User" if msg.get("role") == "user" else "Assistant"
                conversation += f"{role}: {msg.get('content')}\n"
        
        # ThÃªm tin nháº¯n hiá»‡n táº¡i
        conversation += f"User: {message}\nAssistant:"
        
        return conversation
    
    def generate_response(self, conversation: str) -> str:
        """
        Gá»i Gemini API Ä‘á»ƒ táº¡o response
        
        Args:
            conversation: Chuá»—i conversation Ä‘áº§y Ä‘á»§
            
        Returns:
            str: Response tá»« AI
            
        Raises:
            Exception: Náº¿u cÃ³ lá»—i khi gá»i API
        """
        # ThÃªm timeout 30s Ä‘á»ƒ trÃ¡nh request bá»‹ treo
        response = self.model.generate_content(
            conversation,
            request_options={"timeout": 30}
        )
        return response.text
    
    def chat(self, message: str, conversation_history: List[Dict] = None) -> str:
        """
        Method chÃ­nh Ä‘á»ƒ chat vá»›i AI
        
        Args:
            message: Tin nháº¯n tá»« user
            conversation_history: Lá»‹ch sá»­ há»™i thoáº¡i (optional)
            
        Returns:
            str: Response tá»« AI
        """
        if conversation_history is None:
            conversation_history = []
        
        # Giá»›i háº¡n lá»‹ch sá»­ chá»‰ giá»¯ 5 tin nháº¯n gáº§n nháº¥t Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i
        conversation_history = conversation_history[-5:] if len(conversation_history) > 5 else conversation_history

        # Truy xuáº¥t cÃ´ng viá»‡c báº±ng vector search (chá»‰ láº¥y top 3 job liÃªn quan nháº¥t)
        jobs = search_jobs_vector(message, top_k=3)
        jobs_info = "\n".join([f"- {job}" for job in jobs]) if jobs else ""
        
        # XÃ¢y dá»±ng conversation
        conversation = self.build_conversation(message, conversation_history, jobs_info)
        
        # Debug log (optional)
        print("\n" + "=" * 50)
        print("ðŸ“ Conversation sent to AI:")
        print(conversation)
        print("=" * 50)
        
        # Gá»i API
        ai_response = self.generate_response(conversation)
        
        # Debug log
        print("\nðŸ¤– AI Response:")
        print(ai_response)
        print("=" * 50 + "\n")
        
        return ai_response


# Singleton instance
_gemini_service = None

def get_gemini_service() -> GeminiService:
    """
    Láº¥y instance cá»§a GeminiService (singleton pattern)
    """
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiService()
    return _gemini_service
